<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="../static/css/bootstrap.min.css" rel="stylesheet">
    <link href="../static/css/app.css" rel="stylesheet">
    <link href="../static/css/bootstrap-suggest.css" rel="stylesheet">
    <script src="../static/js/jquery-3.4.1.min.js"></script>
    <script src="../static/js/bootstrap.min.js"></script>
    <script src="../static/js/bootstrap-suggest.js"></script>
    <script src="../static/js/app.js"></script>


    <link href="https://fonts.googleapis.com/css?family=Josefin+Sans:300|Open+Sans:300|Oxygen|Material+Icons" rel="stylesheet">
</head>


<body>
    <div class="overlay">
        <div class="spinner-border text-primary" role="status"><span class="sr-only">Loading...</span></div>
    </div>
    <h2> Deep Learning in Action </h2>
    <div class="row">
        <div class="col-sm-1"></div>

        <div class="col-sm-10">
            <center>
                <h3>Question Answering with Transformers </h3>
            </center>
            <h3><b>Help <a href="/">[Homepage]</a></b></h3>
            <h4><b>Usage</b></h4>
            <br>
            <h5><b>Custom entry</b></h5>
            Enter a prompt/short paragraph, a question about the given prompt, and a few choices (upto 4). Press predict, and the predictions of the models will be shown.
            <br>
            <br>
            <h5><b>Random entry</b></h5>
            If you want to see random examples from the Cosmos QA dataset, you can press one of the Random Question buttons. Validation questions have labels so the correct answer will be displayed. On the other hand, the test questions do not, and thus will not display the correct answer.
            <br>
            <br>
            <h5><b>Top k entries</b></h5>
            By default, only the models top prediction will be shown. If you would like to see more choices, increase the slider.
            <br>
            <br>
            <h4><b>Models</b></h4>
            <h5><b>Unified QA (3B and large)</b></h5>
            Unified QA is a T5 based model that has been trained on over 30 language tasks, including BoolQ, CommonsenseQA, MultiRC, PhysicalIQA, and Quoref among others. UnifiedQA is the SOTA the following:
            <ul>
                <li>AI2 Reasoning Challenge</li>
                <li>ROPES</li>
                <li>Question Answering via Sentence Composition (QASC)</li>
                <li>OpenBookQA Dataset</li>
                <li>Physical IQA (2nd best to UNICORN [another T5 model]. 89.5% accuracy, Best non-T5: 79.6%)</li>
                <li>Social IQA (2nd best to UNICORN.)</li>
                <li>WinoGrande (2nd best to UNICORN)</li>
            </ul>
            <h5><b>T5 (3B and large)</b></h5>
            This model is the original T5 finetuned on Cosmos QA using the same technique as the 2nd best performing model on Cosmos QA (Surprisingly, it is also second to UNICORN).
            <br>
            <br>
            <h5><b>XLM RoBERTa</b></h5>
            XLM-RoBERTa is a multilingual model trained on 100 different languages. XLM-RoBERTa has <b>NOT</b> been finetuned for this question answering task.
            <br>
            <br>
            <h5><b>RoBERTa</b></h5>
            RoBERTa is an optimized version of bert which achieved the SOTA on SQuAD, GLUE, and RACE upon release.
            <br>
            <br>

</body>
</html>